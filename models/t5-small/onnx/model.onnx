import { pipeline } from '@xenova/transformers';
import { env } from '@xenova/transformers';

env.localModelPath = './models/'; // Tell the app where the lightweight files (tokenizer, config) are located.

async function loadModel() {
    // If model.onnx is missing locally, download it from HuggingFace and cache it
    const generator = await pipeline('text-generation', 'Xenova/t5-small', {
        // Auto-download missing files and store them locally
        cache: true, 
        progress_callback: (progress) => console.log(`Downloading: ${Math.round(progress * 100)}%`)
    });

    // Example text generation with the downloaded model
    const result = await generator('Translate this text to French: Hello, how are you?');
    console.log(result);
}

loadModel();

